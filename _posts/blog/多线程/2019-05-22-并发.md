---
layout: post
title: 并发
categories: 多线程
description: 并发编程的挑战、并发机制的实现原理与应用，包括volatile的应用、synchronized的实现原理与应用、原子操作的实现原理  
keywords: 并发的挑战、并发原理、volatile应用、synchronized原理、原子类实现原理
---
## 1.并发编程的挑战
&emsp;&emsp;并发编程的目的是为了让程序运行得更快，但是，并不是启动更多的线程就能让程序最大限度地并发执行。在进行并发编程时，
如果希望通过多线程执行任务让程序运行得更快，会面临非常多的挑战，比如上下文切换的问题、死锁的问题，以及受限于硬件和软件的
资源限制问题，下面介绍几种并发编程的挑战以及解决方案。
## 1.1 上下文切换
&emsp;&emsp;即使是单核处理器也支持多线程执行代码，CPU通过给每个线程分配CPU时间片来实现这个机制。时间片是CPU分配给各个线程的时间，
因为时间片非常短，所以CPU通过不停地切换线程执行，让我们感觉多个线程是同时执行的，时间片一般是几十毫秒（ms）。  
1) 并发执行不一定比串行执行快，因为线程有创建和上下文切换的开销  
2) 减少上下文切换的方法有无锁并发编程、CAS算法、使用最少线程和使用协程。  

- 无锁并发编程。多线程竞争锁时，会引起上下文切换，所以多线程处理数据时，可以用一些办法来避免使用锁，如将数据的ID按照Hash算法
取模分段，不同的线程处理不同段的数据。  
- CAS算法。Java的Atomic包使用CAS算法来更新数据，而不需要加锁。  
- 使用最少线程。避免创建不需要的线程，比如任务很少，但是创建了很多线程来处理，这样会造成大量线程都处于等待状态。  
- 协程：在单线程里实现多任务的调度，并在单线程里维持多个任务间的切换。  

## 1.2 死锁
&emsp;&emsp;锁是个非常有用的工具，运用场景非常多，因为它使用起来非常简单，而且易于理解。但同时它也会带来一些困扰，那就是可能会引起死锁，
一旦产生死锁，就会造成系统功能不可用。比如t1拿到锁之后，因为一些异常情况没有释放锁（死循环）。又或者是t1拿到一个数据库锁，
释放锁的时候抛出了异常，没释放掉。  
<br/>
现在我们介绍避免死锁的几个常见方法：

- 避免一个线程同时获取多个锁  
- 避免一个线程在锁内同时占用多个资源，尽量保证每个锁只占用一个资源  
- 尝试使用定时锁，使用lock.tryLock（timeout）来替代使用内部锁机制  
- 对于数据库锁，加锁和解锁必须在一个数据库连接里，否则会出现解锁失败的情况  

## 1.3 资源的限制
1) 什么是资源限制  
资源限制是指在进行并发编程时，程序的执行速度受限于计算机硬件资源或软件资源。
例如，服务器的带宽只有2Mb/s，某个资源的下载速度是1Mb/s每秒，系统启动10个线程下载资源，下载速度不会变成10Mb/s，所以在进行并发
编程时，要考虑这些资源的限制。硬件资源限制有带宽的上传/下载速度、硬盘读写速度和CPU的处理速度。软件资源限制有数据库的连接
数和socket连接数等。    
<br/>
2) 资源限制引发的问题  
在并发编程中，将代码执行速度加快的原则是将代码中串行执行的部分变成并发执行，但是如果将某段串行的代码并发执行，因为受限于资源，
仍然在串行执行，这时候程序不仅不会加快执行，反而会更慢，因为增加了上下文切换和资源调度的时间。例如，之前看到一段程
序使用多线程在办公网并发地下载和处理数据时，导致CPU利用率达到100%，几个小时都不能运行完成任务，后来修改成单线程，一个小时就执
行完成了。  
<br/>
3) 如何解决资源限制的问题  
对于硬件资源限制，可以考虑使用集群并行执行程序。既然单机的资源有限制，那么就让程序在多机上运行。比如使用ODPS、Hadoop或者自己
搭建服务器集群，不同的机器处理不同的数据。可以通过“数据ID%机器数”，计算得到一个机器编号，然后由对应编号的机器处理这笔数据。
对于软件资源限制，可以考虑使用资源池将资源复用。比如使用连接池将数据库和Socket连接复用，或者在调用对方webservice接口获取数据
时，只建立一个连接。  
<br/>
4) 在资源限制情况下进行并发编程  
如何在资源限制的情况下，让程序执行得更快呢？方法就是，根据不同的资源限制调整程序的并发度，比如下载文件程序依赖于两个资源——
带宽和硬盘读写速度。有数据库操作时，涉及数据库连接数，如果SQL语句执行非常快，而线程的数量比数据库连接数大很多，则
某些线程会被阻塞，等待数据库连接。  
<br/>
&emsp;&emsp;CPU通过时间片分配算法来循环执行任务，当前任务执行一个时间片后会切换到下一个任务。但是，在切换前会保存上一个任务的状态，
以便下次切换回这个任务时，可以再加载这个任务的状态。所以任务从保存到再加载的过程就是一次上下文切换。  
<br/>
&emsp;&emsp;这就像我们同时读两本书，当我们在读一本英文的技术书时，发现某个单词不认识，于是便打开中英文字典，但是在放下英文技术书之前，
大脑必须先记住这本书读到了多少页的第多少行，等查完单词之后，能够继续读这本书。这样的切换是会影响读书效率的，同样上下文
切换也会影响多线程的执行速度。  
## 2.并发机制的底层实现原理
Java代码在编译后会变成Java字节码，字节码被类加载器加载到JVM里，JVM执行字节码，最终需要转化为汇编指令在CPU上执行，Java中所使用
的并发机制依赖于JVM的实现和CPU的指令。
#### 2.1 volatile的实现原理
volatile是轻量级的synchronized，它在多处理器开发中保证了共享变量的“可见性”。可见性的意思是当一个线程修改一个共享变量时，
另外一个线程能读到这个修改的值。如果volatile变量修饰符使用恰当的话，它比synchronized的使用和执行成本更低，因为它不会引起线程上下文的切换和调度。
<br/>
volatile的定义：Java编程语言允许线程访问共享变量，为了确保共享变量能被准确和一致地更新，线程应该确保通过排他锁单独获得这个变量。
Java语言提供了volatile，在某些情况下比锁要更加方便。如果一个字段被声明成volatile，Java线程内存模型确保所有线程看到这个变量的值是一致的。  
在了解volatile实现原理之前，我们先来看下与其实现原理相关的CPU术语与说明。下表是CPU术语的定义。  
| 术语 | 术语描述 |
| ------ | ------ |
| 内存屏障 | 是一组处理器指令，用于实现对内存操作的顺序限制 |
| 缓存行 | 缓存中可以分配的最小存储单位  |
| 原子操作 | 不可中断的一个或一系列操作 |
| 缓存行填充 | 当处理器识别到从内存中读取操作数是可缓存的，处理器读取整个缓存行到适当的缓存 |
| 缓存命中 | 如果进行高速缓存行填充操作的内存位置仍然是下次处理器访问的地址时，处理器从缓存中读取操作数，而不是从内存读取 |
| 写命中 | 当处理器将操作数写回到一个内存缓存的区域时，它首先会检查这个缓存的内存地址是否在缓存行中，如果存在一个有效的缓存行，
则处理器将这个操作数写回到缓存，而不是写到内存，这个操作被称为写命中 |
| 写缺失 | 一个有效的缓存行被写入到不存在的内存区域 |  
<br/>
volatile是如何保证可见性？  
如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令。Lock前缀的指令在多核处理器下会引发了两件事情：  
1）将当前处理器缓存行的数据写回到系统内存。  
2）这个写回内存的操作会使在其他CPU里缓存了该内存地址的数据无效  
<br/>
为了提高处理速度，处理器不直接和内存进行通信，而是先将系统内存的数据读到内部缓存（L1，L2或其他）后再进行操作，但操作完不知道
何时会写到内存。如果对声明了volatile的变量进行写操作，JVM就会向处理器发送一条Lock前缀的指令，将这个变量所在缓存行的数据写回到
系统内存。但是，就算写回到内存，如果其他处理器缓存的值还是旧的，再执行计算操作就会有问题。所以，在多处理器下，为了保证各个处理
器的缓存是一致的，就会实现缓存一致性协议，每个处理器通过嗅探在总线上传播的数据来检查自己缓存的值是不是过期了，当处理器发现自己
缓存行对应的内存地址被修改，就会将当前处理器的缓存行设置成无效状态，当处理器对这个数据进行修改操作的时候，会重新从系统内存中把
数据读到处理器缓存里。  
<br/>
下面来具体讲解volatile的两条实现原则。  
1）Lock前缀指令会引起处理器缓存回写到内存。Lock前缀指令导致在执行指令期间，声言处理器的LOCK#信号。在多处理器环境中，
LOCK#信号确保在声言该信号期间，处理器可以独占任何共享内存。但是，在最近的处理器里，LOCK＃信号一般不锁总线，而是锁缓存，毕
竟锁总线开销的比较大。对于Intel486和Pentium处理器，在锁操作时，总是在总线上声言LOCK#信号。但在P6和目前的处理器中，如果
访问的内存区域已经缓存在处理器内部，则不会声言LOCK#信号。相反，它会锁定这块内存区域的缓存并回写到内存，并使用缓存一致性机制
来确保修改的原子性，此操作被称为“缓存锁定”，缓存一致性机制会阻止同时由两个以上处理器修改缓存的内存区域数据。  
<br/>
2）一个处理器的缓存回写到内存会导致其他处理器的缓存无效。IA-32处理器和Intel 64处理器使用MESI（修改、独占、共享、无效）
控制协议去维护内部缓存和其他处理器缓存的一致性。在多核处理器系统中进行操作的时候，IA-32和Intel 64处理器能嗅探其他处理器访问系统
内存和它们的内部缓存。处理器使用嗅探技术保证它的内部缓存、系统内存和其他处理器的缓存的数据在总线上保持一致。例如，
在Pentium和P6 family处理器中，如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理
器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充。
#### 2.2 Synchronized实现原理
Java中的每一个对象都可以作为锁。具体表现为以下3种形式：  
- 对于普通同步方法，锁是当前实例对象。  
注：当一个线程正在访问一个对象的 synchronized 实例方法，那么其他线程不能访问该对象的其他 synchronized 方法，
毕竟一个对象只有一把锁，当一个线程获取了该对象的锁之后，其他线程无法获取该对象的锁，所以无法访问该对象的其他synchronized实例方法  
- 对于静态同步方法，锁是当前类的Class对象。  
注：如果一个线程A调用一个实例对象的非static synchronized方法，而线程B需要调用这个实例对象所属类的静态 synchronized方法，
是允许的，因为锁不同，一个是当前类的class对象，一个是当前实例的对象。  
- 对于同步方法块，锁是Synchonized括号里配置的对象。  
方法体可能比较大，同时存在一些比较耗时的操作，而需要同步的代码又只有一小部分，此时可以使用同步代码块的方式对需要同步的代码进行包裹。  
<br/>
 
**JVM基于进入和退出Monitor对象来实现方法同步和代码块同步，但两者的实现细节不一样。代码块同步是使用monitorenter
和monitorexit指令实现的，而方法同步是由方法调用指令读取运行时常量池中方法的 ACC_SYNCHRONIZED 标志来隐式实现的。**  
<br/>
monitorenter指令是在编译后插入到同步代码块的开始位置，而monitorexit是插入到方法结束处和异常处，JVM要保证每个monitorenter必须
有对应的monitorexit与之配对。任何对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。线程执行到monitorenter
指令时，将会尝试获取对象所对应的monitor的所有权，即尝试获得对象的锁。  

##### 2.2.1 Java对象头与Monitor
在JVM中，对象在内存中的布局分为三块区域：对象头、实例数据和对齐填充。如下：  
![](/images/posts/多线程/)   
- 实例变量：存放类的属性数据信息，包括父类的属性信息，如果是数组的实例部分还包括数组的长度，这部分内存按4字节对齐。  
- 填充数据：由于虚拟机要求对象起始地址必须是8字节的整数倍。填充数据不是必须存在的，仅仅是为了字节对齐。  
- 对象头：synchronized用的锁是存在Java对象头里的。如果对象是数组类型，则虚拟机用3个字宽（Word）存储对象头，如果对象是非数组类型，
则用2字宽存储对象头。在32位虚拟机中，1字宽等于4字节，即32bit。其由Mark Word、Class Metadata Address 和 array length
(对象是数组类型才会有该字段)组成，如下表所示(以32位JVM为例)：
![](/images/posts/多线程/对象头结构.png)  
<br/>
在运行期间，Mark Word里存储的数据会随着锁标志位的变化而变化，如下表所示Mark Word结构(以32位为例)：
![](/images/posts/多线程/对象头结构-Mark%20Word.png)  
##### 2.2.1 重量级锁，synchronized
锁标识位为10，其中指针指向的是monitor对象（也称为管程或监视器锁）的起始地址。每个对象都存在着一个 monitor 与之关联，
对象与其 monitor 之间的关系存在多种实现方式，如monitor可以与对象一起创建销毁或当线程试图获取对象锁时自动生成，但当一个 monitor 被某个线程持有后，它便处于锁定状态。在Java虚拟机(HotSpot)中，monitor是由ObjectMonitor实现的，其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的）
##### 2.2.1 锁的升级与对比
Java SE 1.6为了减少获得锁和释放锁带来的性能消耗，引入了“偏向锁”和“轻量级锁”，在Java SE 1.6中，锁一共有4种状态，级别从低到高依
次是：无锁状态、偏向锁状态、轻量级锁状态和重量级锁状态，这几个状态会随着竞争情况逐渐升级。锁可以升级但不能降级，意味着偏向锁
升级成轻量级锁后不能降级成偏向锁。这种锁升级却不能降级的策略，目的是为了提高获得锁和释放锁的效率，下文会详细分析。  
**(1) 偏向锁**  
经研究发现，大多数情况下，锁不仅不存在多线程竞争，而且总是由同一线程多次获得，为了让线程获得锁的代价更低而引入了偏向锁。
当一个线程访问同步块并获取锁时，会在对象头和栈帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出同步块时不需要进行CAS
操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。
如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；
如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程。  
<br/>
**偏向锁的撤销**  
<br/>
偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。偏向锁的撤销，
需要等待全局安全点（在这个时间点上没有正在执行的字节码）。它会首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，
如果线程不处于活动状态，则将对象头设置成无锁状态；如果线程仍然活着，拥有偏向锁的栈会被执行，遍历偏向对象的锁记录，
栈中的锁记录和对象头的Mark Word要么重新偏向于其他线程，要么恢复到无锁或者标记对象不适合作为偏向锁，最后唤醒暂停的线程。  
<br/>
图中的线程1演示了偏向锁初始化的流程，线程2演示了偏向锁撤销的流程。  
![](/images/posts/多线程/)  
<br/>
**(2)轻量级锁**  
- 轻量级锁加锁  
线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，
官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失
败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁。  
- 轻量级锁解锁  
轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，
锁就会膨胀成重量级锁。
图2-2是两个线程同时争夺锁，导致锁膨胀的流程图。  
![](/images/posts/多线程/)  
因为自旋会消耗CPU，为了避免无用的自旋（比如获得锁的线程被阻塞住了），一旦锁升级成重量级锁，就不会再恢复到轻量级锁状态。
当锁处于这个状态下，其他线程试图获取锁时，都会被阻塞住，当持有锁的线程释放锁之后会唤醒这些线程，被唤醒的线程就会进行新一轮
的夺锁之争。  
<br/>
**(3)锁的优缺点对比**  
