---
layout: post
title: Hadoop与HBase的前生今世
categories: BigData
description: Hadoop与HBase各自扮演的角色
keywords: Hadoop, HBase
---


## 引子：
古代，人们用牛来拉重物。当一头牛拉不动一根圆木时，他们不曾想过培育更大更壮的牛。
同样：我们也不需要尝试开发超级计算机，而应试着结合使用更多计算机系统。

—— Grace Hopper（计算机软件第一夫人，计算机历史上第一个BUG的发现者，也是史上最大BUG千年虫的制造者）

这就是分布式。




再来看一组令人瞠目结舌的数据：

2012年11月11日

支付宝总交易额191亿元，订单1亿零580万笔，生成15TB日志，访问1931亿次内存数据块，13亿个物理读……

从上面的资料中我们看到了：高性能！高并发！高一致性！高可用性！海量数据！

这就是海量数据处理。远远超出单台计算机的能力范畴。

这就是分布式集群能力的体现，更说明了采用分布式系统的必要性。

## 正文：
单台设备的性能、资源、可扩展性等限制 —— 分布式系统（Hadoop）

传统关系型数据库在面对海量数据时的乏力 —— 分布式数据库（HBase）

关系型数据库，顾名思义，善于处理数据模型间复杂的关系、逻辑、事务。

但在处理海量数据时速度、并发量、可扩展性却惨不忍睹。

当然，我们可以通过巧妙的设计与二次开发来解决上述问题。

速度：分表（减少单表数据量）、缓存查询、静态预生成、提高硬件性能。

并发量：打破单机（或双机）模式，组建数据库集群。

可扩展性：复杂的数据迁移方案。
这个过程想必相当痛苦，而且由于技术约束，造成的用户体验也不够好。

比如我们查银行账单、手机话费的历史记录，总要先选择指定的月份或时间范围，然后点提交。

这就是分表带来的用户体验下降。

## 什么是Hadoop：
而在原生的分布式系统中，整个集群的节点间共享计算、存储、IO资源，完美的解决了性能、并发、数据存储问题。

看一组关于Google的资料（约在2010年）：

Google共有36个数据中心。其中美国有19个、欧洲12个、俄罗斯1个、南美1个和亚洲3个（北京-Google.cn<这个……>、香港-Google.com.hk和东京各1个）。
数据中心以集装箱为单位，每个数据中心有众多集装箱，每个集装箱里面有1160台服务器。
如何使这么多台服务器协同工作？

Google的三大核心元素：
　　1、Google文件系统（GFS）
　　2、Google大表；Bigtable：是Google一种对于半结构化数据进行分布存储与访问的接口或服务）；由于Google的文件系统异常庞大，以至于甲骨文和IBM公司的商业数据库在方面无用武之地。另外，商业数据库都是按 CPU数量来收费，如果Google使用商业数据库，可想而知，这是一笔天文数字。所以，Google量体裁衣地设计了符合自身的大表。
　　3、Mapreduce 算法；它是Google开发的C++编程工具，用于大于1TB数据的大规模数据集并行运算。MapReduce能够找出一个词语在Google搜索目录中 出现的次数；一系列网页中特定词语出现的频率；链接到某个特定网站的所有网站数量等。

好用的东西，总能找到对应的开源实现，这就是Hadoop。